{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train_path = 'data/train.csv'\n",
    "test_path = 'data/test.csv'\n",
    "sample_submission_path = 'data/sample_submission.csv'\n",
    "\n",
    "# Read data\n",
    "train_df = pd.read_csv(train_path)\n",
    "test_df = pd.read_csv(test_path)\n",
    "sample_submission = pd.read_csv(sample_submission_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "def preprocess_and_engineer_features(df):\n",
    "    # Date and time features\n",
    "    df['trans_date'] = pd.to_datetime(df['trans_date'])\n",
    "    df['trans_year'] = df['trans_date'].dt.year\n",
    "    df['trans_month'] = df['trans_date'].dt.month\n",
    "    df['trans_day'] = df['trans_date'].dt.day\n",
    "    df['trans_weekday'] = df['trans_date'].dt.weekday\n",
    "    df['is_weekend'] = df['trans_weekday'].isin([5, 6]).astype(int)\n",
    "    \n",
    "    # Calculate distance between user and merchant\n",
    "    df['distance'] = np.sqrt((df['lat'] - df['merch_lat'])**2 + (df['long'] - df['merch_long'])**2)\n",
    "    \n",
    "    # Log-transform transaction amount\n",
    "    df['log_amt'] = np.log1p(df['amt'])\n",
    "    \n",
    "    # Extract age from DOB\n",
    "    df['dob'] = pd.to_datetime(df['dob'])\n",
    "    df['age'] = (df['trans_date'] - df['dob']).dt.days // 365\n",
    "    \n",
    "    # Encode categorical features\n",
    "    df = pd.get_dummies(df, columns=['category', 'gender', 'state'], drop_first=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess datasets\n",
    "train_df = preprocess_and_engineer_features(train_df)\n",
    "test_df = preprocess_and_engineer_features(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "target = 'is_fraud'\n",
    "features = train_df.drop(columns=['id', 'trans_num', 'trans_date', 'trans_time', 'dob', 'is_fraud'])\n",
    "test_features = test_df.drop(columns=['id', 'trans_num', 'trans_date', 'trans_time', 'dob'])\n",
    "\n",
    "# Separate numerical and categorical columns\n",
    "numerical_cols = features.select_dtypes(include=['float64', 'int64']).columns\n",
    "categorical_cols = features.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Define preprocessing for numerical and categorical features\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Combine preprocessors\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Preprocess the data\n",
    "X = features\n",
    "y = train_df[target]\n",
    "X_test = test_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1-Score: 0.7955\n",
      "Submission file 'submission.csv' created successfully.\n"
     ]
    }
   ],
   "source": [
    "# Train-test split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply the preprocessor\n",
    "X_train = preprocessor.fit_transform(X_train)\n",
    "X_val = preprocessor.transform(X_val)\n",
    "X_test = preprocessor.transform(X_test)\n",
    "\n",
    "# Train the model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_val_pred = model.predict(X_val)\n",
    "val_f1 = f1_score(y_val, y_val_pred)\n",
    "print(f\"Validation F1-Score: {val_f1:.4f}\")\n",
    "\n",
    "# Predict on the test dataset\n",
    "test_predictions = model.predict(X_test)\n",
    "\n",
    "# Create the submission file\n",
    "submission = sample_submission.copy()\n",
    "submission['is_fraud'] = test_predictions\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(\"Submission file 'submission.csv' created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
